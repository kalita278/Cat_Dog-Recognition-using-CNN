{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "525262a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32ba72ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.7.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc03235",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83a014e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#Preprocesing the training set\n",
    "train_data_generator = ImageDataGenerator(rescale=1./255,shear_range=0.2,zoom_range=0.2,horizontal_flip=True)\n",
    "train_data_set = train_data_generator.flow_from_directory('D:/Users/dell1/Desktop/CERTIFICATES/Deep learning/CNN/Section+40+-+Convolutional+Neural+Networks+(CNN)/Section 40 - Convolutional Neural Networks (CNN)/dataset/training_set',target_size=(64,64),batch_size=32,class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd048413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#Preprocessing the testing set\n",
    "test_data_generator = ImageDataGenerator(rescale=1./255)\n",
    "test_set = test_data_generator.flow_from_directory('D:/Users/dell1/Desktop/CERTIFICATES/Deep learning/CNN/Section+40+-+Convolutional+Neural+Networks+(CNN)/Section 40 - Convolutional Neural Networks (CNN)/dataset/test_set',target_size=(64,64),batch_size=\n",
    "                                                  32,class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6cfd94",
   "metadata": {},
   "source": [
    "# Building a CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7598ae47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initializing the CNN\n",
    "cnn = tf.keras.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fbd7cd64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convolution\n",
    "cnn.add(tf.keras.layers.Conv2D(filters= 32,kernel_size=(3,3),activation = 'relu',input_shape=[64,64,3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d49811be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pooling\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides =2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c0ce6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding the 2nd convolutional layer\n",
    "cnn.add(tf.keras.layers.Conv2D(filters= 32,kernel_size=(3,3),activation = 'relu'))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides =2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "799445dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Flattening\n",
    "cnn.add(tf.keras.layers.Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd37cd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Full Connetion \n",
    "cnn.add(tf.keras.layers.Dense(units= 128, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "78c83cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Full Connetion (2nd layer of ANN)\n",
    "cnn.add(tf.keras.layers.Dense(units= 128, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b6d6b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding output layer\n",
    "cnn.add(tf.keras.layers.Dense(units=1,activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4cd5bccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compiling the CNN\n",
    "cnn.compile(optimizer='adam',loss='binary_crossentropy', metrics=['Accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "33053371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "250/250 [==============================] - 124s 493ms/step - loss: 0.6502 - Accuracy: 0.6054 - val_loss: 0.5857 - val_Accuracy: 0.6935\n",
      "Epoch 2/25\n",
      "250/250 [==============================] - 43s 174ms/step - loss: 0.5781 - Accuracy: 0.6923 - val_loss: 0.5613 - val_Accuracy: 0.7200\n",
      "Epoch 3/25\n",
      "250/250 [==============================] - 45s 180ms/step - loss: 0.5346 - Accuracy: 0.7304 - val_loss: 0.5236 - val_Accuracy: 0.7405\n",
      "Epoch 4/25\n",
      "250/250 [==============================] - 45s 180ms/step - loss: 0.5143 - Accuracy: 0.7480 - val_loss: 0.5050 - val_Accuracy: 0.7600\n",
      "Epoch 5/25\n",
      "250/250 [==============================] - 46s 182ms/step - loss: 0.4975 - Accuracy: 0.7624 - val_loss: 0.4890 - val_Accuracy: 0.7830\n",
      "Epoch 6/25\n",
      "250/250 [==============================] - 45s 180ms/step - loss: 0.4718 - Accuracy: 0.7736 - val_loss: 0.4698 - val_Accuracy: 0.7770\n",
      "Epoch 7/25\n",
      "250/250 [==============================] - 46s 185ms/step - loss: 0.4533 - Accuracy: 0.7830 - val_loss: 0.4728 - val_Accuracy: 0.7655\n",
      "Epoch 8/25\n",
      "250/250 [==============================] - 46s 185ms/step - loss: 0.4387 - Accuracy: 0.7934 - val_loss: 0.4927 - val_Accuracy: 0.7675\n",
      "Epoch 9/25\n",
      "250/250 [==============================] - 47s 188ms/step - loss: 0.4322 - Accuracy: 0.7944 - val_loss: 0.4760 - val_Accuracy: 0.7765\n",
      "Epoch 10/25\n",
      "250/250 [==============================] - 46s 183ms/step - loss: 0.4009 - Accuracy: 0.8139 - val_loss: 0.4454 - val_Accuracy: 0.7985\n",
      "Epoch 11/25\n",
      "250/250 [==============================] - 47s 188ms/step - loss: 0.4025 - Accuracy: 0.8130 - val_loss: 0.4606 - val_Accuracy: 0.7955\n",
      "Epoch 12/25\n",
      "250/250 [==============================] - 48s 190ms/step - loss: 0.3885 - Accuracy: 0.8234 - val_loss: 0.4463 - val_Accuracy: 0.7935\n",
      "Epoch 13/25\n",
      "250/250 [==============================] - 47s 187ms/step - loss: 0.3717 - Accuracy: 0.8316 - val_loss: 0.5408 - val_Accuracy: 0.7685\n",
      "Epoch 14/25\n",
      "250/250 [==============================] - 47s 189ms/step - loss: 0.3530 - Accuracy: 0.8430 - val_loss: 0.4442 - val_Accuracy: 0.8085\n",
      "Epoch 15/25\n",
      "250/250 [==============================] - 47s 189ms/step - loss: 0.3462 - Accuracy: 0.8430 - val_loss: 0.4773 - val_Accuracy: 0.8035\n",
      "Epoch 16/25\n",
      "250/250 [==============================] - 48s 191ms/step - loss: 0.3345 - Accuracy: 0.8506 - val_loss: 0.5143 - val_Accuracy: 0.7920\n",
      "Epoch 17/25\n",
      "250/250 [==============================] - 48s 191ms/step - loss: 0.3146 - Accuracy: 0.8656 - val_loss: 0.5324 - val_Accuracy: 0.7870\n",
      "Epoch 18/25\n",
      "250/250 [==============================] - 48s 194ms/step - loss: 0.3010 - Accuracy: 0.8684 - val_loss: 0.4986 - val_Accuracy: 0.8000\n",
      "Epoch 19/25\n",
      "250/250 [==============================] - 48s 192ms/step - loss: 0.2976 - Accuracy: 0.8662 - val_loss: 0.5512 - val_Accuracy: 0.7755\n",
      "Epoch 20/25\n",
      "250/250 [==============================] - 48s 191ms/step - loss: 0.2796 - Accuracy: 0.8846 - val_loss: 0.5031 - val_Accuracy: 0.8015\n",
      "Epoch 21/25\n",
      "250/250 [==============================] - 49s 196ms/step - loss: 0.2650 - Accuracy: 0.8880 - val_loss: 0.5441 - val_Accuracy: 0.7930\n",
      "Epoch 22/25\n",
      "250/250 [==============================] - 49s 195ms/step - loss: 0.2633 - Accuracy: 0.8864 - val_loss: 0.5648 - val_Accuracy: 0.7775\n",
      "Epoch 23/25\n",
      "250/250 [==============================] - 48s 192ms/step - loss: 0.2411 - Accuracy: 0.8969 - val_loss: 0.6026 - val_Accuracy: 0.7980\n",
      "Epoch 24/25\n",
      "250/250 [==============================] - 48s 193ms/step - loss: 0.2406 - Accuracy: 0.8979 - val_loss: 0.5721 - val_Accuracy: 0.7925\n",
      "Epoch 25/25\n",
      "250/250 [==============================] - 48s 190ms/step - loss: 0.2358 - Accuracy: 0.9028 - val_loss: 0.5846 - val_Accuracy: 0.7985\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2a2d0cb10d0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training the CNN and evaluate with testing set\n",
    "cnn.fit(x=train_data_set,validation_data=test_set,epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f3bb9529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat\n"
     ]
    }
   ],
   "source": [
    "#Making a single prediction\n",
    "from keras.preprocessing import image\n",
    "test_img = image.load_img('D:/Users/dell1/Desktop/CERTIFICATES/cat10.jpg',target_size=(64,64,3))\n",
    "test_img = image.img_to_array(test_img)\n",
    "test_img = np.expand_dims(test_img,axis=0)\n",
    "result = cnn.predict(test_img/255.0)\n",
    "if result[0][0] > 0.5:\n",
    "    print('dog')\n",
    "else:\n",
    "    print('cat')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
