{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "525262a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32ba72ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.7.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc03235",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83a014e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#Preprocesing the training set\n",
    "train_data_generator = ImageDataGenerator(rescale=1./255,shear_range=0.2,zoom_range=0.2,horizontal_flip=True)\n",
    "train_data_set = train_data_generator.flow_from_directory('D:/Users/dell1/Desktop/CERTIFICATES/Deep learning/CNN/Section+40+-+Convolutional+Neural+Networks+(CNN)/Section 40 - Convolutional Neural Networks (CNN)/dataset/training_set',target_size=(64,64),batch_size=32,class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd048413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#Preprocessing the testing set\n",
    "test_data_generator = ImageDataGenerator(rescale=1./255)\n",
    "test_set = test_data_generator.flow_from_directory('D:/Users/dell1/Desktop/CERTIFICATES/Deep learning/CNN/Section+40+-+Convolutional+Neural+Networks+(CNN)/Section 40 - Convolutional Neural Networks (CNN)/dataset/test_set',target_size=(64,64),batch_size=\n",
    "                                                  32,class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6cfd94",
   "metadata": {},
   "source": [
    "# Building a CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7598ae47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initializing the CNN\n",
    "cnn = tf.keras.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fbd7cd64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convolution\n",
    "cnn.add(tf.keras.layers.Conv2D(filters= 32,kernel_size=(3,3),activation = 'relu',input_shape=[64,64,3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d49811be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pooling\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides =2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c0ce6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding the 2nd convolutional layer\n",
    "cnn.add(tf.keras.layers.Conv2D(filters= 32,kernel_size=(3,3),activation = 'relu'))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides =2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "799445dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Flattening\n",
    "cnn.add(tf.keras.layers.Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd37cd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Full Connetion \n",
    "cnn.add(tf.keras.layers.Dense(units= 128, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "78c83cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Full Connetion (2nd layer of ANN)\n",
    "cnn.add(tf.keras.layers.Dense(units= 128, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b6d6b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding output layer\n",
    "cnn.add(tf.keras.layers.Dense(units=1,activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4cd5bccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compiling the CNN\n",
    "cnn.compile(optimizer='adam',loss='binary_crossentropy', metrics=['Accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "33053371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "250/250 [==============================] - 95s 378ms/step - loss: 0.6685 - Accuracy: 0.5905 - val_loss: 0.6014 - val_Accuracy: 0.6925\n",
      "Epoch 2/25\n",
      "250/250 [==============================] - 95s 378ms/step - loss: 0.5943 - Accuracy: 0.6823 - val_loss: 0.6358 - val_Accuracy: 0.6565\n",
      "Epoch 3/25\n",
      "250/250 [==============================] - 74s 296ms/step - loss: 0.5501 - Accuracy: 0.7181 - val_loss: 0.5510 - val_Accuracy: 0.7225\n",
      "Epoch 4/25\n",
      "250/250 [==============================] - 47s 188ms/step - loss: 0.5124 - Accuracy: 0.7485 - val_loss: 0.5264 - val_Accuracy: 0.7340\n",
      "Epoch 5/25\n",
      "250/250 [==============================] - 46s 186ms/step - loss: 0.4885 - Accuracy: 0.7626 - val_loss: 0.5495 - val_Accuracy: 0.7260\n",
      "Epoch 6/25\n",
      "250/250 [==============================] - 71s 284ms/step - loss: 0.4780 - Accuracy: 0.7732 - val_loss: 0.4932 - val_Accuracy: 0.7690\n",
      "Epoch 7/25\n",
      "250/250 [==============================] - 61s 243ms/step - loss: 0.4597 - Accuracy: 0.7795 - val_loss: 0.4745 - val_Accuracy: 0.7775\n",
      "Epoch 8/25\n",
      "250/250 [==============================] - 50s 202ms/step - loss: 0.4436 - Accuracy: 0.7940 - val_loss: 0.4577 - val_Accuracy: 0.7850\n",
      "Epoch 9/25\n",
      "250/250 [==============================] - 49s 197ms/step - loss: 0.4325 - Accuracy: 0.8001 - val_loss: 0.4691 - val_Accuracy: 0.7785\n",
      "Epoch 10/25\n",
      "250/250 [==============================] - 82s 327ms/step - loss: 0.4164 - Accuracy: 0.8094 - val_loss: 0.5293 - val_Accuracy: 0.7475\n",
      "Epoch 11/25\n",
      "250/250 [==============================] - 104s 417ms/step - loss: 0.3996 - Accuracy: 0.8149 - val_loss: 0.4517 - val_Accuracy: 0.8025\n",
      "Epoch 12/25\n",
      "250/250 [==============================] - 61s 246ms/step - loss: 0.3909 - Accuracy: 0.8211 - val_loss: 0.5135 - val_Accuracy: 0.7785\n",
      "Epoch 13/25\n",
      "250/250 [==============================] - 49s 195ms/step - loss: 0.3763 - Accuracy: 0.8269 - val_loss: 0.5126 - val_Accuracy: 0.7745\n",
      "Epoch 14/25\n",
      "250/250 [==============================] - 49s 198ms/step - loss: 0.3585 - Accuracy: 0.8409 - val_loss: 0.5642 - val_Accuracy: 0.7340\n",
      "Epoch 15/25\n",
      "250/250 [==============================] - 50s 199ms/step - loss: 0.3461 - Accuracy: 0.8491 - val_loss: 0.5131 - val_Accuracy: 0.7790\n",
      "Epoch 16/25\n",
      "250/250 [==============================] - 49s 197ms/step - loss: 0.3264 - Accuracy: 0.8589 - val_loss: 0.5401 - val_Accuracy: 0.7760\n",
      "Epoch 17/25\n",
      "250/250 [==============================] - 50s 202ms/step - loss: 0.3134 - Accuracy: 0.8619 - val_loss: 0.5205 - val_Accuracy: 0.7870\n",
      "Epoch 18/25\n",
      "250/250 [==============================] - 55s 218ms/step - loss: 0.2986 - Accuracy: 0.8725 - val_loss: 0.5464 - val_Accuracy: 0.7790\n",
      "Epoch 19/25\n",
      "250/250 [==============================] - 50s 201ms/step - loss: 0.2938 - Accuracy: 0.8727 - val_loss: 0.4969 - val_Accuracy: 0.7905\n",
      "Epoch 20/25\n",
      "250/250 [==============================] - 51s 205ms/step - loss: 0.2794 - Accuracy: 0.8776 - val_loss: 0.5073 - val_Accuracy: 0.7830\n",
      "Epoch 21/25\n",
      "250/250 [==============================] - 57s 227ms/step - loss: 0.2655 - Accuracy: 0.8875 - val_loss: 0.5516 - val_Accuracy: 0.7830\n",
      "Epoch 22/25\n",
      "250/250 [==============================] - 61s 243ms/step - loss: 0.2475 - Accuracy: 0.8963 - val_loss: 0.5742 - val_Accuracy: 0.7925\n",
      "Epoch 23/25\n",
      "250/250 [==============================] - 59s 236ms/step - loss: 0.2429 - Accuracy: 0.8997 - val_loss: 0.6552 - val_Accuracy: 0.7520\n",
      "Epoch 24/25\n",
      "250/250 [==============================] - 54s 218ms/step - loss: 0.2251 - Accuracy: 0.9091 - val_loss: 0.6084 - val_Accuracy: 0.7895\n",
      "Epoch 25/25\n",
      "250/250 [==============================] - 53s 213ms/step - loss: 0.2157 - Accuracy: 0.9115 - val_loss: 0.5651 - val_Accuracy: 0.7965\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x28c96377dc0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training the CNN and evaluate with testing set\n",
    "cnn.fit(x=train_data_set,validation_data=test_set,epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f3bb9529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog\n"
     ]
    }
   ],
   "source": [
    "#Making a single prediction\n",
    "from keras.preprocessing import image\n",
    "test_img = image.load_img('C:/Users/dell1/Cat or Dog recognition using CNN/download.jfif',target_size=(64,64,3))\n",
    "test_img = image.img_to_array(test_img)\n",
    "test_img = np.expand_dims(test_img,axis=0)\n",
    "result = cnn.predict(test_img/255.0)\n",
    "if result[0][0] > 0.5:\n",
    "    print('dog')\n",
    "else:\n",
    "    print('cat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "234dd13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the model\n",
    "cnn.save('cnn.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2b0388ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the model\n",
    "loaded_model = tf.keras.models.load_model('C:/Users/dell1/Cat or Dog recognition using CNN/cnn.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "59bcf627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cat\n"
     ]
    }
   ],
   "source": [
    "z =image.load_img('C:/Users/dell1/Cat or Dog recognition using CNN/cat.jfif',target_size=(64,64,3))\n",
    "z=image.img_to_array(z)\n",
    "z=np.expand_dims(z,axis=0)\n",
    "x = loaded_model.predict(z/255.0)\n",
    "if x[0][0] > 0.5:\n",
    "    print('Dog')\n",
    "else:\n",
    "    print('Cat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e13f84b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
